{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- <p align=\"center\">\n",
    "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Logo-gustave-roussy.jpg/1200px-Logo-gustave-roussy.jpg\" alt=\"Logo 1\" width=\"250\"/>\n",
    "  <img src=\"https://upload.wikimedia.org/wikipedia/en/thumb/3/3f/Qube_Research_%26_Technologies_Logo.svg/1200px-Qube_Research_%26_Technologies_Logo.svg.png\" alt=\"Logo 2\" width=\"200\" style=\"margin-left: 20px;\"/>\n",
    "</p> -->\n",
    "\n",
    "# Data Challenge : Leukemia Risk Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*GOAL OF THE CHALLENGE and WHY IT IS IMPORTANT:*\n",
    "\n",
    "The goal of the challenge is to **predict disease risk for patients with blood cancer**, in the context of specific subtypes of adult myeloid leukemias. The risk is measured through the **overall survival** of patients, i.e. the duration of survival from the diagnosis of the blood cancer to the time of death or last follow-up. The performance metric used in the challenge is the **IPCW-C-Index**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "*THE DATASETS*\n",
    "\n",
    "The **training set is made of 3,323 patients**. The **test set is made of 1,193 patients**. For each patient, you have acces to CLINICAL data and MOLECULAR data. The details of the data are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- OUTCOME:\n",
    "  * OS_YEARS = Overall survival time in years\n",
    "  * OS_STATUS = 1 (death) , 0 (alive at the last follow-up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- CLINICAL DATA, with one line per patient:\n",
    "  \n",
    "  * ID = unique identifier per patient\n",
    "  * CENTER = clinical center\n",
    "  * BM_BLAST = Bone marrow blasts in % (blasts are abnormal blood cells)\n",
    "  * WBC = White Blood Cell count in Giga/L \n",
    "  * ANC = Absolute Neutrophil count in Giga/L\n",
    "  * MONOCYTES = Monocyte count in Giga/L\n",
    "  * HB = Hemoglobin in g/dL\n",
    "  * PLT = Platelets coutn in Giga/L\n",
    "  * CYTOGENETICS = A description of the karyotype observed in the blood cells of the patients, measured by a cytogeneticist. Cytogenetics is the science of chromosomes. A karyotype is performed from the blood tumoral cells. The convention for notation is ISCN (https://en.wikipedia.org/wiki/International_System_for_Human_Cytogenomic_Nomenclature). Cytogenetic notation are: https://en.wikipedia.org/wiki/Cytogenetic_notation. Note that a karyotype can be normal or abnornal. The notation 46,XX denotes a normal karyotype in females (23 pairs of chromosomes including 2 chromosomes X) and 46,XY in males (23 pairs of chromosomes inclusing 1 chromosme X and 1 chromsome Y). A common abnormality in the blood cancerous cells might be for exemple a loss of chromosome 7 (monosomy 7, or -7), which is typically asssociated with higher risk disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO side note : mesures sont dans des échelles différentes donc attention à normaliser et standardiser les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- GENE MOLECULAR DATA, with one line per patient per somatic mutation. Mutations are detected from the sequencing of the blood tumoral cells. \n",
    "We call somatic (= acquired) mutations the mutations that are found in the tumoral cells but not in other cells of the body.\n",
    "\n",
    "  * ID = unique identifier per patient\n",
    "  * CHR START END = position of the mutation on the human genome\n",
    "  * REF ALT = reference and alternate (=mutant) nucleotide\n",
    "  * GENE = the affected gene\n",
    "  * PROTEIN_CHANGE = the consequence of the mutation on the protei that is expressed by a given gene\n",
    "  * EFFECT = a broad categorization of the mutation consequences on a given gene.\n",
    "  * VAF = Variant Allele Fraction = it represents the **proportion** of cells with the deleterious mutations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.metrics import concordance_index_censored , concordance_index_ipcw\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sksurv.util import Surv\n",
    "\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for \"now\"\n",
    "import datetime\n",
    "def now_str():\n",
    "    now = datetime.datetime.now()\n",
    "    return now.strftime(\"%Y-%m-%d_%H-%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files in the directory\n",
    "# print(os.listdir(\".\"))\n",
    "\n",
    "# Clinical Data\n",
    "# TODO : adapting to my local path\n",
    "df = pd.read_csv(\"../data/X_train/clinical_train.csv\")\n",
    "df_eval = pd.read_csv(\"../data/X_test/clinical_test.csv\")\n",
    "\n",
    "# Molecular Data\n",
    "maf_df = pd.read_csv(\"../data/X_train/molecular_train.csv\")\n",
    "maf_eval = pd.read_csv(\"../data/X_test/molecular_test.csv\")\n",
    "\n",
    "target_df = pd.read_csv(\"../data/target_train.csv\")\n",
    "# TODO: sera fourni le 15 ou le 17 mars\n",
    "# target_df_test = pd.read_csv(\"./target_test.csv\")\n",
    "\n",
    "# Preview the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data Preparation (clinical data only)\n",
    "\n",
    "For survival analysis, we’ll format the dataset so that OS_YEARS represents the time variable and OS_STATUS represents the event indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Starting of Data Cleaning and Preprocessing\n",
    "\n",
    "# Drop rows where 'OS_YEARS' is NaN if conversion caused any issues\n",
    "# initial shape\n",
    "# print(target_df.shape)\n",
    "# drop rows with missing values\n",
    "target_df.dropna(subset=['OS_YEARS', 'OS_STATUS'], inplace=True)\n",
    "# final shape\n",
    "# print(target_df.shape)\n",
    "# percentage of rows dropped:\n",
    "print(f'Percentage of initially dropt rows {(1 - target_df.shape[0] / df.shape[0]) * 100:.2f}%')\n",
    "\n",
    "# Check the data types to ensure 'OS_STATUS' is boolean and 'OS_YEARS' is numeric\n",
    "print(target_df[['OS_STATUS', 'OS_YEARS']].dtypes)\n",
    "\n",
    "# Contarget_dfvert 'OS_YEARS' to numeric if it isn’t already\n",
    "target_df['OS_YEARS'] = pd.to_numeric(target_df['OS_YEARS'], errors='coerce')\n",
    "\n",
    "# Ensure 'OS_STATUS' is boolean\n",
    "target_df['OS_STATUS'] = target_df['OS_STATUS'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature Selection :\n",
    "\n",
    "# Zero : features they selected for the Benchmark model :\n",
    "features_basic = ['BM_BLAST', 'HB', 'PLT']\n",
    "# TODO : Accuracies for each implemented model % set of features used, or if there is regularization or not...\n",
    "\n",
    "# First: Naively add all the features  (except the Cytogenetics column):\n",
    "# features= ['BM_BLAST', 'HB', 'PLT', 'WBC', 'ANC', 'MONOCYTES']\n",
    "# Very naive : slight improvement\n",
    "\n",
    "# Second : construct some features based on scientific knowledge, and add them to the dataframe and the features list\n",
    "df['BLAST_per_WBC'] = df['BM_BLAST'] / (df['WBC'] + 1e-8)\n",
    "df['ANC_per_WBC'] = df['ANC'] / (df['WBC'] + 1e-8)\n",
    "# df['MONOCYTES_per_WBC'] = df['MONOCYTES'] / df['WBC']           # too much missing values, first drop it, then see how to exploit it\n",
    "df[\"PL_per_HB\"] = df['PLT'] / (df['HB'] + 1e-8)\n",
    "# add these features to the features list\n",
    "features_additional = ['BLAST_per_WBC', 'ANC_per_WBC', 'PL_per_HB']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la meme pour le df_eval\n",
    "df_eval['BLAST_per_WBC'] = df_eval['BM_BLAST'] / (df_eval['WBC'] + 1e-8)\n",
    "df_eval['ANC_per_WBC'] = df_eval['ANC'] / (df_eval['WBC'] + 1e-8)\n",
    "df_eval[\"PL_per_HB\"] = df_eval['PLT'] / (df_eval['HB'] + 1e-8)\n",
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.B : Working on cytogenetic column data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define patterns for key cytogenetic abnormalities\n",
    "cytogenetic_markers = {\n",
    "    \"Has_Monosomy_7\": r\"-7\",\n",
    "    \"Has_Trisomy_8\": r\"\\+8\",\n",
    "    \"Has_Del_5q\": r\"del\\(5\\)\",\n",
    "    \"Has_Del_20q\": r\"del\\(20\\)\",\n",
    "    \"Has_Del_17p\": r\"del\\(17\\)\",\n",
    "    \"Has_T_3_3\": r\"t\\(3;3\\)\",\n",
    "    \"Has_Complex_Karyotype\": r\"complex\",\n",
    "    \"Has_Trisomy_21\": r\"\\+21\",\n",
    "    \"Has_Trisomy_22\": r\"\\+22\",\n",
    "    \"Has_T_9_11\": r\"t\\(9;11\\)\",\n",
    "    \"Has_T_15_17\": r\"t\\(15;17\\)\",\n",
    "    \"Has_Inv_3\": r\"inv\\(3\\)\"\n",
    "}\n",
    "# TODO : quand les patterns ne correspondent pas exactement genre \"del(5)\" et \"del(5q)\"\n",
    "\n",
    "# Function to extract cytogenetic abnormalities as separate binary features\n",
    "def extract_cytogenetic_features(cytogenetics):\n",
    "    features = {}\n",
    "    \n",
    "    # If missing or empty, set all to 0\n",
    "    if pd.isna(cytogenetics) or cytogenetics.strip() == \"\":\n",
    "        for key in cytogenetic_markers:\n",
    "            features[key] = 0\n",
    "        features[\"Complexity_Score\"] = 0\n",
    "        return features\n",
    "\n",
    "    cytogenetics = cytogenetics.upper()\n",
    "    \n",
    "    # Check for each abnormality\n",
    "    for key, pattern in cytogenetic_markers.items():\n",
    "        features[key] = int(bool(re.search(pattern, cytogenetics)))\n",
    "\n",
    "    # Compute complexity score (count of detected abnormalities)\n",
    "    features[\"Complexity_Score\"] = sum(features.values())\n",
    "\n",
    "    return features\n",
    "\n",
    "# Apply function to create new binary columns\n",
    "cyto_features_df = df[\"CYTOGENETICS\"].apply(extract_cytogenetic_features).apply(pd.Series)\n",
    "\n",
    "# Merge new binary cytogenetic features into the main dataframe\n",
    "df = pd.concat([df, cyto_features_df], axis=1)\n",
    "\n",
    "# Drop the original cytogenetics column (no longer needed)\n",
    "df.drop(columns=[\"CYTOGENETICS\"], inplace=True)\n",
    "\n",
    "# Display updated dataframe with binary cytogenetic features\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same for the eval set\n",
    "cyto_features_df_eval = df_eval[\"CYTOGENETICS\"].apply(extract_cytogenetic_features).apply(pd.Series)\n",
    "df_eval = pd.concat([df_eval, cyto_features_df_eval], axis=1)\n",
    "df_eval.drop(columns=[\"CYTOGENETICS\"], inplace=True)\n",
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cytogenetics = list(cyto_features_df.columns)\n",
    "print(\"The cytogenetic data are :\", features_cytogenetics)\n",
    "print(len(features_cytogenetics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_eval.shape)\n",
    "print(df.shape)\n",
    "# So we overall added 13 features to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.A : Process Molecular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load molecular data\n",
    "mutation_data = maf_df.copy()  # Assuming maf_df contains molecular variants\n",
    "\n",
    "# One-hot encode gene mutations\n",
    "mutation_features = mutation_data.pivot_table(index='ID', columns='GENE', values='VAF', aggfunc='max').fillna(0)\n",
    "\n",
    "# One-hot encode mutation effects\n",
    "mutation_effects = pd.get_dummies(mutation_data[['ID', 'EFFECT']], columns=['EFFECT']).groupby('ID').sum()\n",
    "\n",
    "# Update feature list\n",
    "molecular_features = list(mutation_features.columns)\n",
    "molecular_effect = list(mutation_effects.columns)\n",
    "# molecular_package = molecular_features + molecular_effect\n",
    "# molecular_features = list(mutation_features.columns) + list(mutation_effects.columns)\n",
    "print(df.shape)\n",
    "print(mutation_effects.shape)\n",
    "print(mutation_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same to the eval set\n",
    "mutation_data_eval = maf_eval.copy()\n",
    "mutation_features_eval = mutation_data_eval.pivot_table(index='ID', columns='GENE', values='VAF', aggfunc='max').fillna(0)\n",
    "mutation_effects_eval = pd.get_dummies(mutation_data_eval[['ID', 'EFFECT']], columns=['EFFECT']).groupby('ID').sum()\n",
    "\n",
    "# define the list of molecular features of the eval set\n",
    "molecular_features_eval = list(mutation_features_eval.columns)\n",
    "molecular_effect_eval = list(mutation_effects_eval.columns)\n",
    "# molecular_package_eval = molecular_features_eval + molecular_effect_eval\n",
    "print(df_eval.shape)\n",
    "print(mutation_effects_eval.shape)\n",
    "print(mutation_features_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to ge the common molecular features between the train and the eval set\n",
    "common_molecular_features = set(molecular_features).intersection(set(molecular_features_eval))\n",
    "print(\"The number of common molecular feature is\", len(common_molecular_features))\n",
    "\n",
    "# # now I want to merge df to maf_df and df_eval to maf_evaln only on the common features\n",
    "# print(list(common_molecular_features))\n",
    "# print(mutation_features.columns)\n",
    "df = df.merge(mutation_features[list(common_molecular_features)], on='ID', how='left').fillna(0)\n",
    "df_eval = df_eval.merge(mutation_features_eval[list(common_molecular_features)], on='ID', how='left').fillna(0)\n",
    "\n",
    "common_molecular_effect = set(molecular_effect).intersection(set(molecular_effect_eval))\n",
    "print(\"The number of common molecular effect is\",len(common_molecular_effect))\n",
    "df = df.merge(mutation_effects[list(common_molecular_effect)], on='ID', how='left').fillna(0)\n",
    "df_eval = df_eval.merge(mutation_effects_eval[list(common_molecular_effect)], on='ID', how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_molecular_info = list(common_molecular_features) + list(common_molecular_effect)\n",
    "features = features_basic + features_additional + features_cytogenetics + list_molecular_info\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "df_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : est ce que any csv has been affected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the features\n",
    "TODO : need to implement feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = features_basic\n",
    "# features = features_basic + features_additional\n",
    "# features = features_basic + features_additional + features_cytogenetics\n",
    "\n",
    "print(\"The features are:\", features)\n",
    "target = ['OS_YEARS', 'OS_STATUS']\n",
    "print(len(features))\n",
    "\n",
    "# print(len(molecular_features))\n",
    "# TODO : faire comparaison entre le nombre de features et la taille de nos datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : I can't take the common colums of the molecular features because they are not in the eval set (mais my split is deterministic.... comment remedier à ça?)\n",
    "\n",
    "# features += molecular_features\n",
    "# print(\"Updated feature set with molecular data:\", features)\n",
    "# print(\"Number of features:\", len(features))   # 147 features ------- est ce que c'est abbérant % nombre de data points?\n",
    "\n",
    "# # Take the list of common columns as the features\n",
    "# features = list(common_columns)\n",
    "# print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the survival data format\n",
    "X = df.loc[df['ID'].isin(target_df['ID']), features]\n",
    "y = Surv.from_dataframe('OS_STATUS', 'OS_YEARS', target_df)\n",
    "\n",
    "print(target_df[['OS_STATUS', 'OS_YEARS']].dtypes)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO : FEATURE SELECTION \n",
    "\n",
    "\n",
    "# try the CoxPHFitter\n",
    "# # Select top 50 best features\n",
    "# from sklearn.feature_selection import SelectKBest\n",
    "# from sklearn.feature_selection import f_regression\n",
    "# selector = SelectKBest(score_func=f_regression, k=50)\n",
    "# X_selected = selector.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : 0 quand on a pas les données -- c'est chaud \n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Splitting the Dataset an,d Z norm\n",
    "We’ll split the data into training and testing sets to evaluate the model’s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute percentage of missing values per column\n",
    "missing_percentage = X_train.isnull().mean() * 100\n",
    "# Print the missing values percentage (genre de manière générale pas selon les catégories)\n",
    "# print(missing_percentage)\n",
    "# define a threshold for dropping columns with missing values\n",
    "threshold = 10\n",
    "# Print the columns with more than 10% missing values\n",
    "# TODO : à voir in next runs\n",
    "print(missing_percentage[missing_percentage > threshold])\n",
    "\n",
    "\n",
    "# TODO : idk if we can do an imputation for the molecular data?????\n",
    "\n",
    "# Survival-aware imputation for missing values\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_train[features] = imputer.fit_transform(X_train[features])\n",
    "X_test[features] = imputer.transform(X_test[features])\n",
    "\n",
    "# TODO : est ce que faut faire chaque impuration pour chaque catégorie de features seules : genre features_cytogenetics, puis features_additional?\n",
    "\n",
    "# Attention additional features have more missing values : \n",
    "# WBC           7.3 %\n",
    "# ANC           4.6 %\n",
    "# MONOCYTES    16.3 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z normalizing the data :\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data_scaler = StandardScaler()\n",
    "# We decide to keep the dataframe format\n",
    "X_train_znorm = pd.DataFrame(data_scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_znorm = pd.DataFrame(data_scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "# DONC : \n",
    "# X_train est un dataframe, NON Z normed\n",
    "# X_train_znorm est un dataframe, Z normed\n",
    "\n",
    "# TODO : est ce quil faut Znorm the y_train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : maybe drop les datas ou ya bcp de manque??\n",
    "\n",
    "# features.remove('PL_per_HB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Training Standard Machine Learning Methods\n",
    "\n",
    "In this step, we train a standard LightGBM model on survival data, but we do not account for censoring. Instead of treating the event status, we use only the observed survival times as the target variable. This approach disregards whether an individual’s event (e.g., death) was observed or censored, effectively treating the problem as a standard regression task. While this method provides a basic benchmark, it may be less accurate than survival-specific models (but still be explored!), as it does not leverage the information contained in censored observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sksurv.util import Surv\n",
    "\n",
    "# Define LightGBM parameters\n",
    "lgbm_params = {\n",
    "    'max_depth': 3,         # TODO : when adding features try to increase the depth of the tree\n",
    "    'learning_rate': 0.05,\n",
    "    'verbose': -1,\n",
    "    # 'alpha': 100,\n",
    "}\n",
    "\n",
    "# Prepare the data for LightGBM\n",
    "# Scale the target (OS_YEARS) to reduce skew, apply weights based on event status\n",
    "X_train_lgb = X_train_znorm  # Features for training\n",
    "y_train_transformed = y_train['OS_YEARS']\n",
    "\n",
    "# Create LightGBM dataset\n",
    "train_dataset = lgb.Dataset(X_train_lgb, label=y_train_transformed)\n",
    "\n",
    "# Train the LightGBM model\n",
    "model = lgb.train(params=lgbm_params, train_set=train_dataset)\n",
    "\n",
    "# Make predictions on the training and testing sets\n",
    "pred_train = -model.predict(X_train_znorm)\n",
    "pred_test = -model.predict(X_test_znorm)\n",
    "\n",
    "# Evaluate the model using Concordance Index IPCW\n",
    "train_ci_ipcw = concordance_index_ipcw(y_train, y_train, pred_train, tau=7)[0]\n",
    "test_ci_ipcw = concordance_index_ipcw(y_train, y_test, pred_test, tau=7)[0]\n",
    "print(f\"LightGBM Survival Model Concordance Index IPCW on train: {train_ci_ipcw:.2f}\")\n",
    "print(f\"LightGBM Survival Model Concordance Index IPCW on test: {test_ci_ipcw:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a standard XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a XGBoost model for survival analysis\n",
    "xgb_params = {\n",
    "    # \"objective\": \"rank:pairwise\",  # Optimized for ranking risk scores\n",
    "    # \"eval_metric\": \"ndcg\",  # Normalized Discounted Cumulative Gain\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.01,\n",
    "    'verbosity': 0,\n",
    "}\n",
    "\n",
    "# Prepare the data for XGBoost\n",
    "X_train_xgb = X_train_znorm\n",
    "y_train_xgb = y_train['OS_YEARS']\n",
    "\n",
    "# Create DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train_xgb, label=y_train_xgb)\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_model = xgb.train(params=xgb_params, dtrain=dtrain, num_boost_round=100)\n",
    "\n",
    "# Make predictions on the training and testing sets\n",
    "dtest_train = xgb.DMatrix(X_train_znorm)\n",
    "dtest_test = xgb.DMatrix(X_test_znorm)\n",
    "pred_train_xgb = -xgb_model.predict(dtest_train)\n",
    "pred_test_xgb = -xgb_model.predict(dtest_test)\n",
    "\n",
    "# Evaluate the model using Concordance Index IPCW\n",
    "train_ci_ipcw_xgb = concordance_index_ipcw(y_train, y_train, pred_train_xgb, tau=7)[0]\n",
    "test_ci_ipcw_xgb = concordance_index_ipcw(y_train, y_test, pred_test_xgb, tau=7)[0]\n",
    "print(f\"XGBoost Survival Model Concordance Index IPCW on train: {train_ci_ipcw_xgb:.2f}\")\n",
    "print(f\"XGBoost Survival Model Concordance Index IPCW on test: {test_ci_ipcw_xgb:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search for the XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'verbosity': [0]\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "# Initialize GridSearchCV with the XGBoost model and parameter grid\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "# TODO : il fait un grid search avec un negative mean squared error\n",
    "\n",
    "# Prepare the data for XGBoost\n",
    "X_train_xgb = X_train\n",
    "y_train_xgb = y_train['OS_YEARS']\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train_xgb, y_train_xgb)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "print(f\"Best score found: {best_score}\")\n",
    "\n",
    "# Train the XGBoost model with the best parameters\n",
    "best_xgb_model = xgb.XGBRegressor(**best_params)\n",
    "best_xgb_model.fit(X_train_xgb, y_train_xgb)\n",
    "\n",
    "# Make predictions on the training and testing sets\n",
    "dtest_train = xgb.DMatrix(X_train)\n",
    "dtest_test = xgb.DMatrix(X_test)\n",
    "pred_train_xgb = -best_xgb_model.predict(dtest_train)\n",
    "pred_test_xgb = -best_xgb_model.predict(dtest_test)\n",
    "\n",
    "# Evaluate the model using Concordance Index IPCW\n",
    "train_ci_ipcw_xgb = concordance_index_ipcw(y_train, y_train, pred_train_xgb, tau=7)[0]\n",
    "test_ci_ipcw_xgb = concordance_index_ipcw(y_train, y_test, pred_test_xgb, tau=7)[0]\n",
    "print(f\"XGBoost Survival Model Concordance Index IPCW on train: {train_ci_ipcw_xgb:.2f}\")\n",
    "print(f\"XGBoost Survival Model Concordance Index IPCW on test: {test_ci_ipcw_xgb:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : save submission file of the lgb, and xgboost methods\n",
    "# TODO : train light gbm with the number of mutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation for LightGBM** \n",
    "\n",
    "- le modèle commence à overfitter sur le train set quand on ajoute des features (ratio des PL et HB et ratios similaires, et aussi cytogenetic data)\n",
    "- il a encore plus overfitté sur le train avec l'ajout des data moléculaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZING THE \n",
    "# \n",
    "# # Assuming the LightGBM model is defined as `model`\n",
    "# plt.figure(figsize=(20, 10))\n",
    "# lgb.plot_tree(model, tree_index=0, figsize=(20, 10), show_info=['split_gain', 'internal_value', 'internal_count', 'leaf_count'])\n",
    "# plt.title(\"First Tree in LightGBM Model\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Cox Proportional Hazards Model\n",
    "\n",
    "To account for censoring in survival analysis, we use a Cox Proportional Hazards (Cox PH) model, a widely used method that estimates the effect of covariates on survival times without assuming a specific baseline survival distribution. The Cox PH model is based on the hazard function, $h(t | X)$, which represents the instantaneous risk of an event (e.g., death) at time $t$ given covariates $X$. The model assumes that the hazard can be expressed as:\n",
    "\n",
    "$$h(t | X) = h_0(t) \\exp(\\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p)$$\n",
    "\n",
    "\n",
    "where $h_0(t)$ is the baseline hazard function, and $\\beta$ values are coefficients for each covariate, representing the effect of $X$ on the hazard. Importantly, the proportional hazards assumption implies that the hazard ratios between individuals are constant over time. This approach effectively leverages both observed and censored survival times, making it a more suitable method for survival data compared to standard regression techniques that ignore censoring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Cox Proportional Hazards model\n",
    "cox = CoxPHSurvivalAnalysis(alpha=10.0)\n",
    "# TODO : ajuster les hyperparamètres\n",
    "cox.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model using Concordance Index IPCW\n",
    "cox_cindex_train = concordance_index_ipcw(y_train, y_train, cox.predict(X_train), tau=7)[0]\n",
    "cox_cindex_test = concordance_index_ipcw(y_train, y_test, cox.predict(X_test), tau=7)[0]\n",
    "print(f\"Cox Proportional Hazard Model Concordance Index IPCW on train: {cox_cindex_train:.2f}\")\n",
    "print(f\"Cox Proportional Hazard Model Concordance Index IPCW on test: {cox_cindex_test:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize and train the Cox Proportional Hazards model\n",
    "# from lifelines import CoxPHFitter\n",
    "# cox2 = CoxPHFitter()\n",
    "# # TODO : ajuster les hyperparamètres\n",
    "# cox2.fit(df, duration_col='OS_YEARS', event_col='OS_STATUS')\n",
    "# # fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate the model using Concordance Index IPCW\n",
    "# cox2_cindex_train = concordance_index_ipcw(y_train, y_train, cox2.predict(X_train), tau=7)[0]\n",
    "# cox2_cindex_test = concordance_index_ipcw(y_train, y_test, cox2.predict(X_test), tau=7)[0]\n",
    "# print(f\"Cox Proportional Hazard Model Concordance Index IPCW on train: {cox2_cindex_train:.2f}\")\n",
    "# print(f\"Cox Proportional Hazard Model Concordance Index IPCW on test: {cox2_cindex_test:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUGGING suggested by chatgpt quand on prend en compte les mutations data :\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "corr_matrix = X_train.corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Feature Correlation Matrix\")\n",
    "# plt.show()\n",
    "\n",
    "# TODO : ya bcp de correlation entre certains features!!!!! dans le petit carré en haut à gauche ----- faire de la feature selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify if there are totally null columns\n",
    "null_columns = X_train.columns[X_train.isnull().all()]\n",
    "print(null_columns)\n",
    "\n",
    "# TODO : feature selection\n",
    "# TODO : expand le recouvrement dans le cas de cytogenetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a threshold of correlation and print all the pairs of features that are highly correlated\n",
    "threshold = 0.7\n",
    "print(len(features))\n",
    "for i in range(len(features)):\n",
    "    for j in range(i+1, len(features)):\n",
    "        if corr_matrix.iloc[i, j] > threshold:\n",
    "            print(f\"Features {features[i]} and {features[j]} are highly correlated with a correlation of {corr_matrix.iloc[i, j]:.2f}\")\n",
    "\n",
    "# print(\"3rd and sixth features are highly correlated\")\n",
    "# print(corr_matrix.iloc[2, 5])\n",
    "# print(\"those features are :\")\n",
    "# print(features[2],\"and\", features[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we have the pairs of highly correlated features, we can drop one of them\n",
    "# Drop the highly correlated features\n",
    "\n",
    "# TODO : attention fix which feature we keep or remove\n",
    "corr_feature = 'PL_per_HB'\n",
    "features.remove(corr_feature)\n",
    "# features.remove('PLT')\n",
    "\n",
    "# update the training and testing sets\n",
    "X_train = X_train.drop(columns=[corr_feature])\n",
    "X_test = X_test.drop(columns=[corr_feature])\n",
    "\n",
    "X = X.drop(columns=[corr_feature])\n",
    "\n",
    "print(len(features))\n",
    "\n",
    "\n",
    "# recompute the correlation matrix\n",
    "corr_matrix = X_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.heatmap(corr_matrix, annot=False, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "# plt.title(\"Feature Correlation Matrix\")\n",
    "\n",
    "threshold = 0.7\n",
    "print(len(features))\n",
    "for i in range(len(features)):\n",
    "    for j in range(i+1, len(features)):\n",
    "        if corr_matrix.iloc[i, j] > threshold:\n",
    "            print(f\"Features {features[i]} and {features[j]} are highly correlated with a correlation of {corr_matrix.iloc[i, j]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Naive Approach to Incorporate Mutations\n",
    "\n",
    "In this step, we take a very naive approach to account for genetic mutations by simply counting the total number of somatic mutations per patient. Instead of analyzing specific mutations or their biological impact, we use this aggregate count as a basic feature to reflect the mutational burden for each individual. Although simplistic, this feature can serve as a general indicator of genetic variability across patients, which may influence survival outcomes. More sophisticated mutation analysis could be incorporated in future models to improve predictive power.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step: Extract the number of somatic mutations per patient\n",
    "# Group by 'ID' and count the number of mutations (rows) per patient\n",
    "tmp = maf_df.groupby('ID').size().reset_index(name='Nmut')\n",
    "\n",
    "# Merge with the training dataset and replace missing values in 'Nmut' with 0\n",
    "df_2 = df.merge(tmp, on='ID', how='left').fillna({'Nmut': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same for the df_eval :\n",
    "# Adding the Nmut feature to the evaluation dataset\n",
    "tmp_eval = maf_eval.groupby('ID').size().reset_index(name='Nmut')\n",
    "\n",
    "# Merge with the training dataset and replace missing values in 'Nmut' with 0\n",
    "df_eval = df_eval.merge(tmp_eval, on='ID', how='left').fillna({'Nmut': 0})\n",
    "\n",
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features\n",
    "# features = ['BM_BLAST', 'HB', 'PLT', 'Nmut']\n",
    "# features = ['BM_BLAST', 'HB', 'PLT', 'WBC', 'ANC', 'MONOCYTES', 'Nmut']\n",
    "# features = features_basic + ['BLAST_per_WBC', 'ANC_per_WBC', 'PL_per_HB', 'Nmut']\n",
    "# features = features_basic + ['Nmut']\n",
    "features = features + ['Nmut']\n",
    "target = ['OS_YEARS', 'OS_STATUS']\n",
    "\n",
    "# Create the survival data format\n",
    "X = df_2.loc[df_2['ID'].isin(target_df['ID']), features]\n",
    "y = Surv.from_dataframe('OS_STATUS', 'OS_YEARS', target_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# TODO : change the random state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival-aware imputation for missing values\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_train[features] = imputer.fit_transform(X_train[features])\n",
    "X_test[features] = imputer.transform(X_test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the features are:\", features)\n",
    "print(\"the number of features:\", len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z normalizing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data_scaler = StandardScaler()\n",
    "X_train_znorm = pd.DataFrame(data_scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_znorm = pd.DataFrame(data_scaler.transform(X_test), columns=X_test.columns, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Cox Proportional Hazards model\n",
    "# cox = CoxPHSurvivalAnalysis()\n",
    "cox = CoxPHSurvivalAnalysis(alpha=10.)\n",
    "# TODO : ajuster les hyperparamètres\n",
    "cox.fit(X_train, y_train)\n",
    "# observation : better results without Z normalization\n",
    "\n",
    "# Evaluate the model using Concordance Index IPCW\n",
    "cox_cindex_train = concordance_index_ipcw(y_train, y_train, cox.predict(X_train), tau=7)[0]\n",
    "cox_cindex_test = concordance_index_ipcw(y_train, y_test, cox.predict(X_test), tau=7)[0]\n",
    "print(f\"Cox Proportional Hazard Model Concordance Index IPCW on train: {cox_cindex_train:.2f}\")\n",
    "print(f\"Cox Proportional Hazard Model Concordance Index IPCW on test: {cox_cindex_test:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 : Random Survival Forest model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Selecting the adequate features for the Random Survival Forest model\n",
    "# features = features_basic + features_additional + features_cytogenetics + ['Nmut']\n",
    "# or just using all the features\n",
    "\n",
    "# # Survival-aware imputation for missing values\n",
    "# imputer = SimpleImputer(strategy=\"median\")\n",
    "# X_train[features] = imputer.fit_transform(X_train[features])\n",
    "# X_test[features] = imputer.transform(X_test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train Random Survival Forest\n",
    "rsf = RandomSurvivalForest(n_estimators=200, min_samples_split=10, min_samples_leaf=5, max_depth=5, random_state=42, oob_score=True)\n",
    "# de base ken n_estimators=200, tried avec 300 too\n",
    "# TODO : what does the oob score do?\n",
    "rsf.fit(X_train_znorm, y_train)\n",
    "# Résultat pareil, qu'on Z- normalise ou pas\n",
    "\n",
    "# Evaluate using IPCW Concordance Index\n",
    "rsf_cindex_train = concordance_index_ipcw(y_train, y_train, rsf.predict(X_train_znorm), tau=7)[0]\n",
    "rsf_cindex_test = concordance_index_ipcw(y_train, y_test, rsf.predict(X_test_znorm), tau=7)[0]\n",
    "\n",
    "print(f\"RSF Concordance Index IPCW on train: {rsf_cindex_train:.2f}\")\n",
    "print(f\"RSF Concordance Index IPCW on test: {rsf_cindex_test:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training for a different horizon : TAU = 5 years\n",
    "# -------------- okay done\n",
    "###### NEXT :\n",
    "# Train on \"the best parameters\" for the Random Survival Forest model (found with GridSearchCV)\n",
    "\n",
    "# Initialize and train Random Survival Forest\n",
    "rsf2 = RandomSurvivalForest(n_estimators=100, min_samples_split=2, min_samples_leaf=1, max_depth=3, random_state=42)\n",
    "rsf2.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate using IPCW Concordance Index\n",
    "rsf2_cindex_train = concordance_index_ipcw(y_train, y_train, rsf2.predict(X_train), tau=7)[0]\n",
    "rsf2_cindex_test = concordance_index_ipcw(y_train, y_test, rsf2.predict(X_test), tau=7)[0]\n",
    "\n",
    "print(f\"RSF Concordance Index IPCW on train: {rsf2_cindex_train:.2f}\")\n",
    "print(f\"RSF Concordance Index IPCW on test: {rsf2_cindex_test:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : regularize the RSF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Best parameters found: {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
    "# # Initialize and train Random Survival Forest\n",
    "# wow = RandomSurvivalForest(n_estimators=100, min_samples_split=2, min_samples_leaf=1, max_depth=3, random_state=42)\n",
    "# wow.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate using IPCW Concordance Index\n",
    "# wow_cindex_train = concordance_index_ipcw(y_train, y_train, wow.predict(X_train), tau=7)[0]\n",
    "# wow_cindex_test = concordance_index_ipcw(y_train, y_test, wow.predict(X_test), tau=7)[0]\n",
    "\n",
    "# print(f\"RSF Concordance Index IPCW on train: {wow_cindex_train:.2f}\")\n",
    "# print(f\"RSF Concordance Index IPCW on test: {wow_cindex_test:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(features))\n",
    "# TODO : maybe mix long and short term predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation for RSF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "# Define a function to compute the IPCW concordance index for cross-validation\n",
    "def ipcw_cindex(estimator, X, y):\n",
    "    predictions = estimator.predict(X)\n",
    "    return concordance_index_ipcw(y, y, predictions, tau=7)[0]\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(rsf, X, y, cv=5, scoring=ipcw_cindex)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(f\"Cross-validation IPCW C-index scores: {cv_scores}\")\n",
    "print(f\"Mean IPCW C-index: {cv_scores.mean():.2f}\")\n",
    "print(f\"Standard Deviation of IPCW C-index: {cv_scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation for the RSF2 model (the one with \"best parameters\")\n",
    "cv_scores2 = cross_val_score(rsf2, X, y, cv=5, scoring=ipcw_cindex)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(f\"Cross-validation IPCW C-index scores: {cv_scores2}\")\n",
    "print(f\"Mean IPCW C-index: {cv_scores2.mean():.2f}\")\n",
    "print(f\"Standard Deviation of IPCW C-index: {cv_scores2.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for the best hyperparameters for RSF\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Define the parameter grid for the Random Survival Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 3, 5]\n",
    "}\n",
    "\n",
    "# Initialize the Random Survival Forest model\n",
    "rsf = RandomSurvivalForest(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV with the RSF model and parameter grid\n",
    "grid_search = GridSearchCV(estimator=rsf, param_grid=param_grid, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "print(f\"Best score found: {best_score}\")\n",
    "\n",
    "# TODO : faire un grid search pour toutes les méthodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************\n",
    "### Inference on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Adding the Nmut feature to the evaluation dataset\n",
    "# tmp_eval = maf_eval.groupby('ID').size().reset_index(name='Nmut')\n",
    "\n",
    "# # Merge with the training dataset and replace missing values in 'Nmut' with 0\n",
    "# df_eval = df_eval.merge(tmp_eval, on='ID', how='left').fillna({'Nmut': 0})\n",
    "\n",
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_eval.drop(columns=\"Nmut_x\", inplace=True)    \n",
    "# df_eval.rename(columns={\"Nmut_y\": \"Nmut\"}, inplace=True)\n",
    "# df_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the features we have selected\n",
    "# print(features)\n",
    "# df_eval.head()\n",
    "df_eval[features] = imputer.transform(df_eval[features])\n",
    "X_eval_znorm = pd.DataFrame(data_scaler.transform(df_eval[features]), columns=features, index=df_eval.index)\n",
    "\n",
    "# cox_prediction_on_test_set = cox.predict(df_eval.loc[:, features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_eval[features] = imputer.transform(df_eval[features])\n",
    "rsf_prediction_on_test_set = rsf.predict(X_eval_znorm.loc[:, features])\n",
    "# lgb_prediction_on_test_set = model.predict(df_eval.loc[:, features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = pd.Series(prediction_on_test_set, index=df_eval['ID'], name='OS_YEARS')\n",
    "# cox_test_submission = pd.Series(cox_prediction_on_test_set, index=df_eval['ID'], name='risk_score')\n",
    "rsf_test_submission = pd.Series(rsf_prediction_on_test_set, index=df_eval['ID'], name='risk_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsf_test_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./output', exist_ok=True)\n",
    "\n",
    "# # I just want the date and hour and minute\n",
    "# import datetime\n",
    "# now = datetime.datetime.now()\n",
    "# now = now.strftime(\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "# submission.to_csv(f'./output/submission_{now}_rsf_ok.csv')\n",
    "# cox_test_submission.to_csv(f'./output/submission_{now_str()}_cox.csv')\n",
    "rsf_test_submission.to_csv(f'./output/submission_{now_str()}_rsf.csv')\n",
    "# submission.to_csv('./output/all_clinical_features_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************\n",
    "### Stacking a meta model on COX + RSF\n",
    "First, trying with a linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load test survival data\n",
    "# rsf_preds = pd.read_csv(\"./output/submission_2025-03-10_00-29_rsf.csv\", index_col=\"ID\")  \n",
    "# cox_preds = pd.read_csv(\"./output/submission_2025-03-10_00-29_cox.csv\", index_col=\"ID\")  \n",
    "\n",
    "# Z-normalize the survival scores obtain by methods RSF and COX, using StandardScaler\n",
    "dd_scaler = StandardScaler()\n",
    "\n",
    "# TODO : Attention : each model has been trained on Znormed ou pas ?!\n",
    "\n",
    "# Train set :\n",
    "rsf_pred_train = dd_scaler.fit_transform(rsf.predict(X_train_znorm).reshape(-1, 1)).flatten()\n",
    "cox_pred_train = dd_scaler.fit_transform(cox.predict(X_train).reshape(-1, 1)).flatten()\n",
    "\n",
    "# Test set :\n",
    "rsf_pred_test = dd_scaler.transform(rsf.predict(X_test_znorm).reshape(-1, 1)).flatten()\n",
    "cox_pred_test = dd_scaler.transform(cox.predict(X_test).reshape(-1, 1)).flatten()\n",
    "\n",
    "# rsf_pred_test = (rsf_pred_test - rsf_pred_test.mean()) / rsf_pred_test.std()\n",
    "# cox_pred_test = (cox_pred_test - cox_pred_test.mean()) / cox_pred_test.std()\n",
    "\n",
    "\n",
    "# Stack RSF & Cox risk scores\n",
    "stacked_X_train = pd.DataFrame({\"rsf_score\": rsf_pred_train, \"cox_score\": cox_pred_train}, index=X_train.index)\n",
    "stacked_X_test = pd.DataFrame({\"rsf_score\": rsf_pred_test, \"cox_score\": cox_pred_test}, index=X_test.index)\n",
    "\n",
    "# Train a meta-learner : logistic regression\n",
    "meta_model = LinearRegression()\n",
    "# TODO : finetuner le LR de la logistic regression par exemple\n",
    "meta_model.fit(stacked_X_train, y_train[\"OS_YEARS\"])\n",
    "\n",
    "# Predict combined survival scores\n",
    "# predict or predict_proba ????\n",
    "ensemble_preds = -meta_model.predict(stacked_X_test)\n",
    "train_ensemble_preds = -meta_model.predict(stacked_X_train)\n",
    "\n",
    "# print(f\"y_train shape: {y_train.shape}\")\n",
    "# print(f\"y_test shape: {y_test.shape}\")\n",
    "# print(f\"ensemble_preds shape: {ensemble_preds.shape}\")\n",
    "\n",
    "# Evaluate IPCW C-index\n",
    "train_ensemble_cindex = concordance_index_ipcw(y_train, y_train, train_ensemble_preds, tau=7)[0]\n",
    "ensemble_cindex = concordance_index_ipcw(y_train, y_test, ensemble_preds, tau=7)[0]\n",
    "print(f\"Linear Meta-Learner IPCW C-index on train: {train_ensemble_cindex:.2f}\")\n",
    "print(f\"Linear Meta-Learner IPCW C-index: {ensemble_cindex}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)\n",
    "# print(y_train[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# did a Z norm maybe before applying the meta model Logistic regression \n",
    "# TODO : feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost as meta-learner on COX + RSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sksurv.metrics import concordance_index_ipcw\n",
    "\n",
    "# Stack RSF & Cox risk scores\n",
    "# non Z norm\n",
    "# stacked_X_train = pd.DataFrame({\"rsf_score\": rsf.predict(X_train), \"cox_score\": cox.predict(X_train)}, index=X_train.index)\n",
    "# stacked_X_test = pd.DataFrame({\"rsf_score\": rsf.predict(X_test), \"cox_score\": cox.predict(X_test)}, index=X_test.index)\n",
    "# Z norm\n",
    "stacked_X_train = pd.DataFrame({\"rsf_score\": rsf_pred_train, \"cox_score\": cox_pred_train}, index=X_train.index)\n",
    "stacked_X_test = pd.DataFrame({\"rsf_score\": rsf_pred_test, \"cox_score\": cox_pred_test}, index=X_test.index)\n",
    "\n",
    "# Convert survival labels to a format usable by XGBoost (duration and event)\n",
    "y_train_event = y_train[\"OS_STATUS\"].astype(int)  # 1 if event occurred, 0 otherwise\n",
    "y_train_time = y_train[\"OS_YEARS\"]  # Survival time\n",
    "\n",
    "# Train an XGBoost model for survival ranking\n",
    "dtrain = xgb.DMatrix(stacked_X_train, label=y_train_time)  # Use time as label for ranking\n",
    "dtest = xgb.DMatrix(stacked_X_test)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"survival:cox\",  # Optimized for ranking risk scores\n",
    "    \"eval_metric\": \"aft-nloglik\",  # Normalized Discounted Cumulative Gain\n",
    "    \"learning_rate\": 0.0001,  # Learning rate\n",
    "    \"max_depth\": 4,  # Small depth to avoid overfitting\n",
    "    \"subsample\": 0.7,  # Use 80% of data per tree\n",
    "    \"colsample_bytree\": 0.7,  # Use 80% of features per tree\n",
    "    \"lambda\": 0.01,  # L2 regularization\n",
    "    \"alpha\": 0.1,  # L1 regularization\n",
    "}\n",
    "\n",
    "xgb_model = xgb.train(params, dtrain, num_boost_round=200)\n",
    "\n",
    "# Predict survival risk scores\n",
    "train_ensemble_preds = xgb_model.predict(dtrain)\n",
    "ensemble_preds = xgb_model.predict(dtest)\n",
    "\n",
    "# Evaluate IPCW C-index\n",
    "# train ipcw c-index\n",
    "ensemble_cindex_train = concordance_index_ipcw(y_train, y_train, train_ensemble_preds, tau=7)[0]\n",
    "# test ipcw c-index\n",
    "ensemble_cindex = concordance_index_ipcw(y_train, y_test, ensemble_preds, tau=7)[0]\n",
    "print(f\"Optimized Meta-Learner IPCW C-index on train: {ensemble_cindex_train}\")\n",
    "print(f\"Optimized Meta-Learner IPCW C-index on test : {ensemble_cindex}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stacked_X_train.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference time\n",
    "\n",
    "# Load test survival data\n",
    "# rsf_preds = pd.read_csv(\"./output/submission_2025-03-10_00-29_rsf.csv\", index_col=\"ID\")\n",
    "# cox_preds = pd.read_csv(\"./output/submission_2025-03-10_00-29_cox.csv\", index_col=\"ID\")  \n",
    "\n",
    "rsf_pred_eval = rsf.predict(X_eval_znorm)\n",
    "cox_pred_eval = cox.predict(df_eval[features])\n",
    "rsf_predd = dd_scaler.transform(rsf_pred_eval.reshape(-1, 1)).flatten()\n",
    "cox_predd = dd_scaler.transform(cox_pred_eval.reshape(-1, 1)).flatten()\n",
    "\n",
    "# print(rsf_predd)\n",
    " \n",
    "# Stack RSF & Cox risk scores of the test set\n",
    "stacked_inference = pd.DataFrame({\"rsf_score\": rsf_predd, \"cox_score\": cox_predd}, index=df_eval.index)\n",
    "# dinference = xgb.DMatrix(stacked_inference)\n",
    "\n",
    "# Predict survival risk scores\n",
    "# inference_preds = xgb_model.predict(dinference)\n",
    "inference_preds = - meta_model.predict(stacked_inference)\n",
    "\n",
    "# Save the submission file\n",
    "submission = pd.Series(inference_preds, index=df_eval['ID'], name='risk_score')\n",
    "submission\n",
    "submission.to_csv(f'./output/submission_meta(cox_rsf)_xgboost_{now_str()}_ensemble.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******************\n",
    "### Step 7 : try combining the 2 models' (COX, RSF) results by hand :\n",
    "genre faire des combinaisons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir('./output')\n",
    "# TODO : test chaque methode seule deja sur la platforme\n",
    "# - tested les resultats de RSF, turns out : it doesn't need to be formatted before\n",
    "\n",
    "\n",
    "# side note for conversion:\n",
    "# # Convert Cox risk scores to survival time estimates\n",
    "# cox_preds[\"survival_time\"] = np.exp(-cox_preds[\"risk_score\"])  # Transforming risk scores\n",
    "# # print(cox_preds.head())\n",
    "\n",
    "\n",
    "# # try to combine, COX and RSF model : classic linear averaging ------------- doesn't work well\n",
    "# from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRYING A NEW STRATEGY TO COMBINE BOTH RESULTS :\n",
    "\n",
    "os.makedirs('./output', exist_ok=True)\n",
    "\n",
    "# Load RSF and Cox predictions\n",
    "rsf_preds = pd.read_csv(\"./output/submission_2025-03-11_19-17_rsf.csv\", index_col=\"ID\")  \n",
    "cox_preds = pd.read_csv(\"./output/submission_2025-03-11_19-17_cox.csv\", index_col=\"ID\") \n",
    "\n",
    "# Standardize RSF and Cox risk scores\n",
    "rsf_preds[\"z_score\"] = (rsf_preds[\"risk_score\"] - rsf_preds[\"risk_score\"].mean()) / rsf_preds[\"risk_score\"].std()\n",
    "cox_preds[\"z_score\"] = (cox_preds[\"risk_score\"] - cox_preds[\"risk_score\"].mean()) / cox_preds[\"risk_score\"].std()\n",
    "\n",
    "# Define weights based on performance\n",
    "w_rsf = 0.8     # 0.745 / (0.745 + 0.72)  # Weight proportional to C-index\n",
    "w_cox = 0.2     # 0.72 / (0.745 + 0.72)\n",
    "# tried with weights (0.8, 0.2) but didn't save or submit the results\n",
    "\n",
    "# Weighted combination using z-scores\n",
    "combined_risk_score = (w_rsf * rsf_preds[\"z_score\"] + w_cox * cox_preds[\"z_score\"])\n",
    "\n",
    "# Store final risk scores\n",
    "final_preds = pd.DataFrame({\"ID\": rsf_preds.index, \"risk_score\": combined_risk_score})\n",
    "# final_preds.to_csv(f\"./output/combined_risk_scores_zscore_{now_str()}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************\n",
    "### Step 8 : Trying a DeepLearning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycox.models import CoxPH\n",
    "import torch\n",
    "from torchtuples.practical import MLPVanilla\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Preparing the data\n",
    "# we have already done the Z normalization : X_train_znorm, X_test_znorm\n",
    "# X_train_znorm est un df et X_train_t est un tensor\n",
    "\n",
    "# Convert data to tensors\n",
    "X_train_t = torch.tensor(X_train_znorm.values, dtype=torch.float32).to(device)\n",
    "X_test_t = torch.tensor(X_test_znorm.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# saving the original y_train de coté\n",
    "y_train_org = y_train.copy()\n",
    "\n",
    "# Ensure target columns are the correct type\n",
    "y_train[\"OS_STATUS\"] = y_train[\"OS_STATUS\"].astype(int)  # Ensure it's an integer\n",
    "y_train[\"OS_YEARS\"] = y_train[\"OS_YEARS\"].astype(float)  # Ensure it's a float\n",
    "\n",
    "# Convert target variables into PyTorch tensors (Manual conversion)\n",
    "y_train_t = (\n",
    "    torch.tensor(y_train[\"OS_YEARS\"].copy(), dtype=torch.float64).to(device),  # Time to event\n",
    "    torch.tensor(y_train[\"OS_STATUS\"].copy(), dtype=torch.int64).to(device)    # Event occurred (1=event, 0=censored)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First implementation sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple MLP model\n",
    "net = MLPVanilla(\n",
    "    in_features=X_train_znorm.shape[1], num_nodes=[64, 32], out_features=1, \n",
    "    batch_norm=True, dropout=0.2, output_bias=False     # dropout =0.4\n",
    ").to(device)\n",
    "# Finetune dropout to prevent overfitting\n",
    "\n",
    "# Train DeepSurv\n",
    "model = CoxPH(net)\n",
    "model.fit(X_train_t, y_train_t, batch_size=128, epochs=300, verbose=False)\n",
    "# TOD : tune the epoch nbr\n",
    "\n",
    "# Predict risk scores\n",
    "deep_risk_scores = model.predict(X_test_t).cpu().detach().numpy()   # Predict risk scores (reverse sign)\n",
    "deep_risk_scores = deep_risk_scores.reshape(-1)\n",
    "\n",
    "\n",
    "# Evaluate\n",
    "# print(len(y_train_t))\n",
    "# print(y_train.shape)\n",
    "# print(y_test.shape)\n",
    "# print(deep_risk_scores.shape)\n",
    "deep_cindex = concordance_index_ipcw(y_train, y_test, deep_risk_scores, tau=7)[0]\n",
    "print(f\"DeepSurv IPCW C-index: {deep_cindex}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search for the DeepSurv approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "param_grid = {\n",
    "    'num_nodes': [[64, 32], [128, 64, 32], [256, 128, 64]],\n",
    "    'dropout': [0.2, 0.3, 0.4],\n",
    "    'lr': [1e-3, 5e-4, 1e-4]\n",
    "}\n",
    "\n",
    "best_cindex = 0\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    net = MLPVanilla(\n",
    "        in_features=X_train.shape[1], \n",
    "        num_nodes=params['num_nodes'], \n",
    "        out_features=1, \n",
    "        batch_norm=True, \n",
    "        dropout=params['dropout'], \n",
    "        output_bias=False\n",
    "    ).to(device)\n",
    "\n",
    "    model = CoxPH(net, optimizer=torch.optim.Adam)\n",
    "\n",
    "    # Set optimizer learning rate\n",
    "    model.optimizer.set_lr(params['lr']) \n",
    "\n",
    "    model.fit(X_train_t, y_train_t, batch_size=128, epochs=300, verbose=False)\n",
    "\n",
    "    deep_risk_scores = model.predict(X_test_t).cpu().detach().numpy().reshape(-1)\n",
    "    cindex = concordance_index_censored(y_test[\"OS_STATUS\"], y_test[\"OS_YEARS\"], deep_risk_scores)[0]\n",
    "    \n",
    "    print(f\"Params: {params} | C-index: {cindex}\")\n",
    "\n",
    "    # Track best parameters\n",
    "    if cindex > best_cindex:\n",
    "        best_cindex = cindex\n",
    "        best_params = params\n",
    "\n",
    "print(f\"Best parameters: {best_params} | Best C-index: {best_cindex}\")\n",
    "\n",
    "# TODO : print both the train and test c-index\n",
    "# TODO : evaluate on the same metric as the other models.....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our optimal params model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on optimal parameters obtained by grid search :\n",
    "# Best parameters: {'dropout': 0.4, 'lr': 0.0001, 'num_nodes': [64, 32]} | Best C-index: 0.7280682581068211\n",
    "\n",
    "# Define a simple MLP model\n",
    "net = MLPVanilla(\n",
    "        in_features=X_train_znorm.shape[1], \n",
    "        num_nodes= [64, 32, 16],\n",
    "        out_features=1, \n",
    "        batch_norm=True, \n",
    "        dropout= 0.2,   #0.4\n",
    "        output_bias=False\n",
    "    ).to(device)\n",
    "# Increasing dropout prevents overfitting\n",
    "\n",
    "# Train DeepSurv\n",
    "deepsurv = CoxPH(net, optimizer=torch.optim.Adam)\n",
    "# Set optimizer learning rate\n",
    "deepsurv.optimizer.set_lr(0.0001)  # 0.0001\n",
    "deepsurv.optimizer.weight_decay = 1e-4  # L2 regularization\n",
    "# TODO : Strong overfitting on the train data\n",
    "\n",
    "deepsurv.fit(X_train_t, y_train_t, batch_size=128, epochs=200, verbose=False)\n",
    "# TODO : tuning the epoch nbr?\n",
    "# TODO : est ce que on peut plot la loss au fur et à mesure? \n",
    "\n",
    "train_deep_risk_scores = deepsurv.predict(X_train_t).cpu().detach().numpy().reshape(-1)\n",
    "test_deep_risk_scores = deepsurv.predict(X_test_t).cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "# # compute train and test c-index\n",
    "# deep_train_cindex = concordance_index_censored(y_train[\"OS_STATUS\"], y_train[\"OS_YEARS\"], train_deep_risk_scores)[0]\n",
    "# deep_test_cindex = concordance_index_censored(y_test[\"OS_STATUS\"], y_test[\"OS_YEARS\"], test_deep_risk_scores)[0]\n",
    "# Compute the train and test ipcw c-index\n",
    "deep_train_cindex = concordance_index_ipcw(y_train, y_train, train_deep_risk_scores, tau=7)[0]\n",
    "deep_test_cindex = concordance_index_ipcw(y_train, y_test, test_deep_risk_scores, tau=7)[0]\n",
    "print(f\"DeepSurv IPCW C-index on train: {deep_train_cindex}\")\n",
    "print(f\"DeepSurv IPCW C-index on test: {deep_test_cindex}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : do we upload the submissions of XGBoost (wahad men li abel bess ayyeh?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "************\n",
    "### Training strategy to be able to stack model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The one RSF :\n",
    "# Initialize the Random Survival Forest\n",
    "rsf_stack = RandomSurvivalForest(n_estimators=200, min_samples_split=10, min_samples_leaf=5, max_depth=5, random_state=42, oob_score=True)\n",
    "\n",
    "# Initialize the DeepSurv model :\n",
    "net_stack = MLPVanilla(\n",
    "        in_features=X_train_znorm.shape[1], \n",
    "        num_nodes= [64, 32],\n",
    "        out_features=1, \n",
    "        batch_norm=True, \n",
    "        dropout= 0.2,   \n",
    "        output_bias=False\n",
    "    ).to(device)\n",
    "# Increasing dropout prevents overfitting\n",
    "\n",
    "# Train DeepSurv\n",
    "deepsurv_stack = CoxPH(net_stack, optimizer=torch.optim.Adam)\n",
    "# Set optimizer learning rate\n",
    "deepsurv_stack.optimizer.set_lr(0.0001)  # 0.0001\n",
    "deepsurv_stack.optimizer.weight_decay = 1e-4  # L2 regularization\n",
    "# TODO : Strong overfitting on the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Z normalizing the data :\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# data_scaler = StandardScaler()\n",
    "# # We decide to keep the dataframe format\n",
    "# X_train_znorm = pd.DataFrame(data_scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "# X_test_znorm = pd.DataFrame(data_scaler.transform(X_test), columns=X_test.columns, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store out-of-fold predictions\n",
    "train_rsf_oof = np.zeros(len(X_train_znorm))\n",
    "train_deepsurv_oof = np.zeros(len(X_train_znorm))\n",
    "# print(train_rsf_oof.shape)\n",
    "# print(train_deepsurv_oof.shape)\n",
    "\n",
    "y_train_org = y_train.copy()\n",
    "# TODO : comment je gere ma data....\n",
    "\n",
    "# Ensure target columns are the correct type\n",
    "y_train[\"OS_STATUS\"] = y_train[\"OS_STATUS\"].astype(int)  # Ensure it's an integer\n",
    "y_train[\"OS_YEARS\"] = y_train[\"OS_YEARS\"].astype(float)  # Ensure it's a float\n",
    "\n",
    "\n",
    "for train_idx, val_idx in kf.split(X_train_znorm):\n",
    "    # selected data :\n",
    "    X_train_selected = X_train_znorm.iloc[train_idx]\n",
    "    X_val_selected = X_train_znorm.iloc[val_idx]\n",
    "\n",
    "    # Train RSF & DeepSurv on K-1 folds\n",
    "    rsf_stack.fit(X_train_selected, y_train[train_idx])\n",
    "    print(\"RSF model trained\")\n",
    "\n",
    "    # compute the RSF risk score on the train set\n",
    "    rsf_train_pred = rsf_stack.predict(X_train_selected).flatten()\n",
    "    # print(rsf_train_pred.shape)\n",
    "    rsf_selected_score = concordance_index_ipcw(y_train_org[train_idx], y_train_org[train_idx], rsf_train_pred, tau=7)[0]\n",
    "    print(f\"RSF IPCW C-index on train: {rsf_selected_score:.2f}\")\n",
    "\n",
    "    # deepsurv takes tensors as inputs\n",
    "    ######################\n",
    "    # Convert data to tensors\n",
    "    X_train_t = torch.tensor(X_train_selected.values, dtype=torch.float32).to(device)\n",
    "    X_val_t = torch.tensor(X_val_selected.values, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Convert target variables into PyTorch tensors (Manual conversion)\n",
    "    y_train_selected_t = (\n",
    "        torch.tensor(y_train['OS_YEARS'][train_idx].copy(), dtype=torch.float64).to(device),  # Time to event\n",
    "        torch.tensor(y_train[\"OS_STATUS\"][train_idx].copy(), dtype=torch.int64).to(device)    # Event occurred (1=event, 0=censored)\n",
    "    )\n",
    "\n",
    "    y_val_selected_t = (\n",
    "        torch.tensor(y_train[\"OS_YEARS\"][val_idx].copy(), dtype=torch.float64).to(device),  # Time to event\n",
    "        torch.tensor(y_train[\"OS_STATUS\"][val_idx].copy(), dtype=torch.int64).to(device)    # Event occurred (1=event, 0=censored)\n",
    "    )\n",
    "    #########################\n",
    "\n",
    "    deepsurv_stack.fit(X_train_t, y_train_selected_t, batch_size=128, epochs=200, verbose=False)\n",
    "    print(\"DeepSurv model trained\")\n",
    "\n",
    "    # compute risk scores\n",
    "    deepsurv_train_pred = deepsurv_stack.predict(X_train_t).cpu().detach().numpy().reshape(-1)\n",
    "    deepsurv_selected_score = concordance_index_ipcw(y_train_org[train_idx], y_train_org[train_idx], deepsurv_train_pred, tau=7)[0]\n",
    "    print(f\"DeepSurv IPCW C-index on train: {deepsurv_selected_score:.2f}\")\n",
    "\n",
    "\n",
    "    #################\n",
    "    # Predict on validation fold\n",
    "    train_rsf_oof[val_idx] = rsf_stack.predict(X_val_selected).flatten()\n",
    "    train_deepsurv_oof[val_idx] = deepsurv_stack.predict(X_val_t).cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "    # compute the RSF risk score on the validation set\n",
    "    rsf_val_pred = rsf_stack.predict(X_val_selected).flatten()\n",
    "    rsf_selected_score = concordance_index_ipcw(y_train_org[val_idx], y_train_org[val_idx], rsf_val_pred, tau=7)[0]\n",
    "    print(f\"RSF IPCW C-index on validation: {rsf_selected_score:.2f}\")\n",
    "\n",
    "    # compute the DeepSurv risk score on the validation set\n",
    "    deepsurv_val_pred = deepsurv_stack.predict(X_val_t).cpu().detach().numpy().reshape(-1)\n",
    "    deepsurv_selected_score = concordance_index_ipcw(y_train_org[val_idx], y_train_org[val_idx], deepsurv_val_pred, tau=7)[0]\n",
    "    print(f\"DeepSurv IPCW C-index on validation: {deepsurv_selected_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the predictions and the score on the X_test and y_test data\n",
    "rsf_test_pred = rsf_stack.predict(X_test_znorm).flatten()\n",
    "rsf_test_score = concordance_index_ipcw(y_train_org, y_test, rsf_test_pred, tau=7)[0]\n",
    "print(f\"RSF IPCW C-index on TEST: {rsf_test_score:.2f}\")\n",
    "\n",
    "# compute the DeepSurv risk score on the \"test\" set\n",
    "deepsurv_test_pred = deepsurv_stack.predict(X_test_t).cpu().detach().numpy().reshape(-1)\n",
    "deepsurv_test_score = concordance_index_ipcw(y_train_org, y_test, deepsurv_test_pred, tau=7)[0]\n",
    "print(f\"DeepSurv IPCW C-index on TEST: {deepsurv_test_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack out-of-fold predictions\n",
    "X_meta_train = np.column_stack((train_rsf_oof, train_deepsurv_oof))\n",
    "# print(X_meta_train.shape)\n",
    "\n",
    "# Train meta-learner\n",
    "# meta_learner = LinearRegression()\n",
    "# meta_learner.fit(X_meta_train, y_train[\"OS_YEARS\"])\n",
    "\n",
    "# Try a XGBoost Regressor :\n",
    "import xgboost as xgb\n",
    "meta_learner = xgb.XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.005, objective='reg:squarederror')\n",
    "meta_learner.fit(X_meta_train, y_train[\"OS_YEARS\"])\n",
    "\n",
    "# Final test predictions\n",
    "test_rsf_preds = rsf_stack.predict(X_test_znorm).flatten()\n",
    "\n",
    "# to tensor\n",
    "X_test_t = torch.tensor(X_test_znorm.values, dtype=torch.float32).to(device)\n",
    "test_deepsurv_preds = deepsurv_stack.predict(X_test_t).cpu().detach().numpy().reshape(-1)\n",
    "# print(test_deepsurv_preds.shape)\n",
    "# print(X_test_znorm.shape)\n",
    "# print(y_test.shape)\n",
    "\n",
    "X_meta_test = np.column_stack((test_rsf_preds, test_deepsurv_preds))\n",
    "\n",
    "# Predict final risk scores\n",
    "final_predictions = -meta_learner.predict(X_meta_test)\n",
    "\n",
    "meta_test_cindex = concordance_index_ipcw(y_train_org, y_test, final_predictions, tau=7)[0]\n",
    "print(f\"Meta-Learner IPCW C-index on test: {meta_test_cindex:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Trying to fit an isotonic regression\n",
    "# from sklearn.isotonic import IsotonicRegression\n",
    "# iso_reg = IsotonicRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Now predict on the platform data\n",
    "# df_eval.head()\n",
    "\n",
    "# Preprocess df_eval (same transformation as training)\n",
    "# apply imputation\n",
    "df_eval[features] = imputer.transform(df_eval[features])\n",
    "\n",
    "# Z normalize the df_eval data\n",
    "X_eval_znorm = pd.DataFrame(data_scaler.transform(df_eval[features]), columns=features, index=df_eval.index)\n",
    "\n",
    "# transform to tensor\n",
    "X_eval_t = torch.tensor(X_eval_znorm.values, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsf_platform_preds = rsf_stack.predict(X_eval_znorm).flatten()\n",
    "\n",
    "# rsf repetition count : \n",
    "tmp_series = pd.Series(rsf_platform_preds)\n",
    "print(tmp_series.value_counts())\n",
    "\n",
    "\n",
    "platform_deepsurv_preds = deepsurv_stack.predict(X_eval_t).cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "X_platform_meta = np.column_stack((rsf_platform_preds, platform_deepsurv_preds))\n",
    "platform_final_preds = -meta_learner.predict(X_platform_meta)\n",
    "\n",
    "platform_submission = pd.Series(platform_final_preds, index=df_eval['ID'], name='risk_score')\n",
    "platform_submission\n",
    "\n",
    "\n",
    "# check if there are repeating values in the submission risk scores\n",
    "print(platform_submission.value_counts())\n",
    "# platform_submission.to_csv(f\"./output/submission_{now_str()}_meta_xgregressor.csv\", header=True)\n",
    "# print(\"Submission file saved as 'submission meta learner regression.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.corrcoef(train_rsf_oof, train_deepsurv_oof)[0, 1]\n",
    "print(f\"Correlation between RSF and DeepSurv: {corr:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation on DeepSurv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "c_indices = []\n",
    "\n",
    "for train_idx, val_idx in kf.split(X_train_znorm):\n",
    "    X_tr, X_val = X_train_znorm.iloc[train_idx], X_train_znorm.iloc[val_idx]\n",
    "    y_tr = y_train[train_idx]\n",
    "    y_val = y_train[val_idx]\n",
    "    \n",
    "    X_tr_t = torch.tensor(X_tr.values, dtype=torch.float32).to(device)\n",
    "    X_val_t = torch.tensor(X_val.values, dtype=torch.float32).to(device)\n",
    "\n",
    "    y_tr_t = (\n",
    "        torch.tensor(y_tr[\"OS_YEARS\"].copy(), dtype=torch.float32).to(device),\n",
    "        torch.tensor(y_tr[\"OS_STATUS\"].copy(), dtype=torch.int64).to(device)\n",
    "    )\n",
    "\n",
    "    # TODO : vérifier les dtype accross diff methods float_cmb\n",
    "    \n",
    "    # TODO : fix this \n",
    "    net = MLPVanilla(\n",
    "        in_features=X_tr.shape[1], num_nodes=[64, 32, 16],\n",
    "        out_features=1, batch_norm=True, dropout=0.2, output_bias=False\n",
    "    ).to(device)\n",
    "    \n",
    "    model = CoxPH(net, optimizer=torch.optim.Adam)\n",
    "    model.optimizer.set_lr(0.0001)\n",
    "    # # TODO : LR et weight decay??\n",
    "    # model.optimizer.set_lr(0.00005)  # 0.0001\n",
    "    model.optimizer.weight_decay = 1e-4  # L2 regularization\n",
    "    \n",
    "    model.fit(X_tr_t, y_tr_t, batch_size=128, epochs=200, verbose=False)\n",
    "    \n",
    "    val_scores = model.predict(X_val_t).cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "    c_index = concordance_index_ipcw(y_tr, y_val, val_scores, tau=7)[0]\n",
    "    print(f\"Validation C-index: {c_index}\")\n",
    "    c_indices.append(c_index)\n",
    "\n",
    "print(f\"Cross-Validation Mean IPCW C-index: {np.mean(c_indices)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After cross validation, we can train the model on the entire training data and make predictions on the test data\n",
    "# question : training all the models on the entire training data? rather than just the train data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting with the DeepSurv model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess df_eval (same transformation as training)\n",
    "# apply imputation\n",
    "df_eval[features] = imputer.transform(df_eval[features])\n",
    "# X_eval = imputer.transform(df_eval[features])     ---- mal noté\n",
    "\n",
    "# Z normalize the df_eval data\n",
    "X_eval_znorm = pd.DataFrame(data_scaler.transform(df_eval[features]), columns=features, index=df_eval.index)\n",
    "\n",
    "# transform to tensor\n",
    "X_eval_t = torch.tensor(X_eval_znorm.values, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict risk scores using DeepSurv\n",
    "eval_deep_risk_scores = model.predict(X_eval_t).cpu().detach().numpy().reshape(-1)  # Convert to 1D\n",
    "\n",
    "# Create submission file\n",
    "deep_test_submission = pd.Series(eval_deep_risk_scores, index=df_eval['ID'], name='risk_score')\n",
    "\n",
    "deep_test_submission\n",
    "\n",
    "# Save as CSV\n",
    "deep_test_submission.to_csv(f\"./output/submission_{now_str()}_deepsurv.csv\", header=True)\n",
    "print(\"Submission file saved as 'submission_date_deepsurv.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : maybe too many epochs genre 200 too much?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a meta model on RSF + DeepSurv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sksurv.metrics import concordance_index_ipcw\n",
    "\n",
    "# Get predictions from RSF and DeepSurv models\n",
    "rsf_train_preds = rsf.predict(X_train_znorm)\n",
    "rsf_test_preds = rsf.predict(X_test_znorm)\n",
    "deepsurv_train_preds = model.predict(X_train_t).cpu().detach().numpy().reshape(-1)\n",
    "deepsurv_test_preds = model.predict(X_test_t).cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "# Stack predictions as features for the meta-learner\n",
    "stacked_train_preds = pd.DataFrame({\n",
    "    'rsf': rsf_train_preds,\n",
    "    'deepsurv': deepsurv_train_preds\n",
    "})\n",
    "\n",
    "stacked_test_preds = pd.DataFrame({\n",
    "    'rsf': rsf_test_preds,\n",
    "    'deepsurv': deepsurv_test_preds\n",
    "})\n",
    "\n",
    "# Train a linear regression model as the meta-learner\n",
    "meta_learner = LinearRegression()\n",
    "meta_learner.fit(stacked_train_preds, y_train['OS_YEARS'])\n",
    "\n",
    "# Get meta-learner predictions\n",
    "meta_train_preds = -meta_learner.predict(stacked_train_preds)\n",
    "meta_test_preds = -meta_learner.predict(stacked_test_preds)\n",
    "\n",
    "# Evaluate the meta-learner using IPCW Concordance Index\n",
    "meta_train_cindex = concordance_index_ipcw(y_train, y_train, meta_train_preds, tau=7)[0]\n",
    "meta_test_cindex = concordance_index_ipcw(y_train, y_test, meta_test_preds, tau=7)[0]\n",
    "\n",
    "print(f\"Meta-Learner IPCW C-index on train: {meta_train_cindex:.2f}\")\n",
    "print(f\"Meta-Learner IPCW C-index on test: {meta_test_cindex:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sksurv.metrics import concordance_index_ipcw\n",
    "\n",
    "# Get predictions from RSF and DeepSurv models\n",
    "rsf_train_preds = rsf.predict(X_train_znorm)\n",
    "rsf_test_preds = rsf.predict(X_test_znorm)\n",
    "deepsurv_train_preds = model.predict(X_train_t).cpu().detach().numpy().reshape(-1)\n",
    "deepsurv_test_preds = model.predict(X_test_t).cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "# # Stack predictions as features for the meta-learner\n",
    "\n",
    "# Z-normalize the RSF and DeepSurv predictions individually\n",
    "rsf_scaler = StandardScaler()\n",
    "deepsurv_scaler = StandardScaler()\n",
    "\n",
    "rsf_train_preds_znorm = rsf_scaler.fit_transform(rsf_train_preds.reshape(-1, 1)).flatten()\n",
    "rsf_test_preds_znorm = rsf_scaler.transform(rsf_test_preds.reshape(-1, 1)).flatten()\n",
    "\n",
    "deepsurv_train_preds_znorm = deepsurv_scaler.fit_transform(deepsurv_train_preds.reshape(-1, 1)).flatten()\n",
    "deepsurv_test_preds_znorm = deepsurv_scaler.transform(deepsurv_test_preds.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Stack normalized predictions as features for the meta-learner\n",
    "stacked_train_preds = pd.DataFrame({\n",
    "    'rsf': rsf_train_preds_znorm,\n",
    "    'deepsurv': deepsurv_train_preds_znorm\n",
    "})\n",
    "\n",
    "stacked_test_preds = pd.DataFrame({\n",
    "    'rsf': rsf_test_preds_znorm,\n",
    "    'deepsurv': deepsurv_test_preds_znorm\n",
    "})\n",
    "\n",
    "# Train a Gradient Boosting Regressor as the meta-learner\n",
    "meta_learner = GradientBoostingRegressor(n_estimators=100, learning_rate=0.005, min_samples_split=10,  max_depth=3, random_state=42, validation_fraction=0.3)\n",
    "meta_learner.fit(stacked_train_preds, y_train['OS_YEARS'])\n",
    "\n",
    "# Get meta-learner predictions\n",
    "meta_train_preds = -meta_learner.predict(stacked_train_preds)\n",
    "meta_test_preds = -meta_learner.predict(stacked_test_preds)\n",
    "\n",
    "# Evaluate the meta-learner using IPCW Concordance Index\n",
    "meta_train_cindex = concordance_index_ipcw(y_train, y_train, meta_train_preds, tau=7)[0]\n",
    "meta_test_cindex = concordance_index_ipcw(y_train, y_test, meta_test_preds, tau=7)[0]\n",
    "\n",
    "print(f\"Meta-Learner IPCW C-index on train: {meta_train_cindex:.2f}\")\n",
    "print(f\"Meta-Learner IPCW C-index on test: {meta_test_cindex:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Grid search on the meta-learner\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.001, 0.005, 0.01],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'validation_fraction': [0.3],\n",
    "    'random_state': [42],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_meta_model = GradientBoostingRegressor()            # TODO : vs XGBRegressor\n",
    "\n",
    "# Initialize GridSearchCV with the XGBoost model and parameter grid\n",
    "grid_search = GridSearchCV(estimator=xgb_meta_model, param_grid=param_grid, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the grid search to the stacked training data\n",
    "grid_search.fit(stacked_train_preds, y_train['OS_YEARS'])\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "print(f\"Best score found: {best_score}\")\n",
    "\n",
    "# Train the XGBoost model with the best parameters\n",
    "best_xgb_meta_model = xgb.XGBRegressor(**best_params)\n",
    "best_xgb_meta_model.fit(stacked_train_preds, y_train['OS_YEARS'])\n",
    "\n",
    "# Get meta-learner predictions\n",
    "meta_train_preds = -best_xgb_meta_model.predict(stacked_train_preds)\n",
    "meta_test_preds = -best_xgb_meta_model.predict(stacked_test_preds)\n",
    "\n",
    "# Evaluate the meta-learner using IPCW Concordance Index\n",
    "meta_train_cindex = concordance_index_ipcw(y_train, y_train, meta_train_preds, tau=7)[0]\n",
    "meta_test_cindex = concordance_index_ipcw(y_train, y_test, meta_test_preds, tau=7)[0]\n",
    "\n",
    "print(f\"Meta-Learner IPCW C-index on train: {meta_train_cindex:.2f}\")\n",
    "print(f\"Meta-Learner IPCW C-index on test: {meta_test_cindex:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set :\n",
    "# Get predictions from RSF and DeepSurv models\n",
    "rsf_test_preds = rsf.predict(X_eval_znorm)\n",
    "deepsurv_test_preds = model.predict(X_eval_t).cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "# Z-normalize the RSF and DeepSurv predictions individually\n",
    "rsf_test_preds_znorm = rsf_scaler.transform(rsf_test_preds.reshape(-1, 1)).flatten()\n",
    "deepsurv_test_preds_znorm = deepsurv_scaler.transform(deepsurv_test_preds.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Stack normalized predictions as features for the meta-learner\n",
    "stacked_test_preds = pd.DataFrame({\n",
    "    'rsf': rsf_test_preds_znorm,\n",
    "    'deepsurv': deepsurv_test_preds_znorm\n",
    "})\n",
    "\n",
    "# Get meta-learner predictions\n",
    "meta_test_preds = -meta_learner.predict(stacked_test_preds)\n",
    "\n",
    "# Create submission file\n",
    "meta_test_submission = pd.Series(meta_test_preds, index=df_eval['ID'], name='risk_score')\n",
    "meta_test_submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the submission\n",
    "meta_test_submission.to_csv(f\"./output/submission_{now_str()}_meta_learner_linear.csv\", header=True)\n",
    "print(\"Submission file saved as 'submission_date_meta_learner.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying the DeepHit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pycox.models import DeepHitSingle\n",
    "\n",
    "# net = MLPVanilla(\n",
    "#     in_features=X_train.shape[1], num_nodes=[64, 32], out_features=1, batch_norm=True, dropout=0.2\n",
    "# ).to(device)\n",
    "\n",
    "# model = DeepHitSingle(net, optimizer=torch.optim.Adam)\n",
    "# model.fit(X_train_t, y_train_t, batch_size=128, epochs=200, verbose=True)\n",
    "\n",
    "# train_hit_risk_scores = model.predict(X_train_t).cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "# # compute train and test c-index\n",
    "# hit_train_cindex = concordance_index_censored(y_train[\"OS_STATUS\"], y_train[\"OS_YEARS\"], train_hit_risk_scores)[0]\n",
    "# print(f\"DeepSurv IPCW C-index on train: {deep_train_cindex}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
